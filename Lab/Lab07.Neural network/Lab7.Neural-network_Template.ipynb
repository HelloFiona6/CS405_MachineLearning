{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB7 Assignment\n",
    "> The document description are designed by JIa Yanhong in 2022. Oct. 20th\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LAB Assignment\n",
    "### Exercise 1 logistic regression\n",
    "This exercise uses dataset digit01.csv , which has 13 columns, and the last column is the dependent variable. \n",
    "\n",
    "This part requires you to implement a `logistic regression` using the pytorch framework (defining a logistic regression class that inherits `nn.module`). To test your model, we provide a dataset `digit01.csv` which is in the **datasets folder**. This dataset requires you to divide the training set and the test set by yourself, and it is recommended that 80% of the training set and 20% of the test set be used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0   1   2   3   4   5   6   7   8   9   10  11  12\n",
       "0   1   1   1   1   0   1   1   0   1   1   1   1   0\n",
       "1   0   1   1   1   0   1   1   0   1   1   1   1   0\n",
       "2   1   1   0   1   0   1   1   0   1   1   1   1   0\n",
       "3   1   1   1   1   0   1   1   0   1   1   1   0   0\n",
       "4   1   1   1   1   0   1   1   0   1   0   1   1   0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "########### Write Your Code Here ###########\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# to suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") \n",
    "df = pd.read_csv(\"datasets/digit01.csv\", header=None)\n",
    "df.head()\n",
    "############################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Splitting dataset into 80% Training and 20% Testing Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 12)\n"
     ]
    }
   ],
   "source": [
    "########### Write Your Code Here ###########\n",
    "y = df[12].values\n",
    "X = df.drop(columns=12).values\n",
    "print(X.shape)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,train_size=0.8, random_state =0)\n",
    "############################################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Define a LogisticRegression subclass of nn. Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a LogisticRegression subclass of nn. Module.\n",
    "########### Write Your Code Here ###########\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "X_train_tensor = torch.FloatTensor(X_train)\n",
    "X_test_tensor = torch.FloatTensor(X_test)\n",
    "y_train_tensor = torch.FloatTensor(y_train).view(-1, 1)\n",
    "y_test_tensor = torch.FloatTensor(y_test).view(-1, 1)\n",
    "\n",
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = nn.Linear(input_size, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return torch.sigmoid(self.linear(x))\n",
    "############################################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### Write Your Code Here ###########\n",
    "input_size = X_train.shape[1]\n",
    "model = LogisticRegression(input_size)\n",
    "############################################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " + Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### Write Your Code Here ###########\n",
    "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
    "############################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ The optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### Write Your Code Here ###########\n",
    "import torch.optim as optim\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "############################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 0.093916\n",
      "200 0.087165\n",
      "300 0.081661\n",
      "400 0.076852\n",
      "500 0.072591\n",
      "600 0.068783\n",
      "700 0.065357\n",
      "800 0.062256\n",
      "900 0.059435\n",
      "1000 0.056858\n",
      "1100 0.054494\n",
      "1200 0.052317\n",
      "1300 0.050306\n",
      "1400 0.048443\n",
      "1500 0.046711\n",
      "1600 0.045098\n",
      "1700 0.043591\n",
      "1800 0.042181\n",
      "1900 0.040859\n",
      "2000 0.039616\n"
     ]
    }
   ],
   "source": [
    "########### Write Your Code Here ###########\n",
    "num_epochs = 2000\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass\n",
    "    outputs = model(X_train_tensor)\n",
    "    loss = loss_fn(outputs, y_train_tensor)\n",
    "    \n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Print loss every 100 epochs\n",
    "    if (epoch+1) % 100 == 0:\n",
    "        print(f'{epoch+1} {loss.item():.6f}')\n",
    "############################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "+ Model Performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 1.0000\n",
      "Test Accuracy: 1.0000\n",
      "Result: y = 0.776317 + -0.853705 x^1 + 2.233681 x^2 + -1.178715 x^3 + -1.755139 x^4 + 1.921055 x^5 + -2.255334 x^6 + -1.313849 x^7 + 1.768014 x^8 + -2.011778 x^9 + -1.789865 x^10 + 2.208385 x^11 + -0.760377 x^12\n"
     ]
    }
   ],
   "source": [
    "########### Write Your Code Here ###########\n",
    "from sklearn.metrics import accuracy_score\n",
    "with torch.no_grad():\n",
    "    y_pred_train = model(X_train_tensor).round()\n",
    "    y_pred_test = model(X_test_tensor).round()\n",
    "    \n",
    "    train_accuracy = accuracy_score(y_train_tensor.numpy(), y_pred_train.numpy())\n",
    "    test_accuracy = accuracy_score(y_test_tensor.numpy(), y_pred_test.numpy())\n",
    "\n",
    "print(f'Train Accuracy: {train_accuracy:.4f}')\n",
    "print(f'Test Accuracy: {test_accuracy:.4f}')\n",
    "weights = model.linear.weight.detach().numpy()[0]  # Convert to numpy array and get the first row\n",
    "bias = model.linear.bias.detach().numpy()[0]        # Convert to numpy array\n",
    "\n",
    "# Prepare the output in a specified format\n",
    "coefficients_str = \" + \".join(f\"{weight:.6f} x^{i+1}\" for i, weight in enumerate(weights))\n",
    "print(f\"Result: y = {bias:.6f} + {coefficients_str}\")\n",
    "\n",
    "############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         6\n",
      "           1       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           1.00        13\n",
      "   macro avg       1.00      1.00      1.00        13\n",
      "weighted avg       1.00      1.00      1.00        13\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#classification report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2  Handwriting recognition with MLP\n",
    "\n",
    "Like last week's lab , your task in this section is also about recognizing handwritten digits, but you are required to use MLP to complete the exercise. It is recommended that you define an MLP class, which is a subclass of `nn.module`.\n",
    "\n",
    "\n",
    "For this exercise we use the `minist` dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### Write Your Code Here ###########\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "def load_mnist_images(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        f.read(16)\n",
    "        images = np.frombuffer(f.read(), dtype=np.uint8)\n",
    "        # 进行reshape，格式为(数量, 高, 宽)\n",
    "        return images.reshape(-1, 28, 28)\n",
    "\n",
    "def load_mnist_labels(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        f.read(8)\n",
    "        labels = np.frombuffer(f.read(), dtype=np.uint8)\n",
    "        return labels\n",
    "    \n",
    "class MNISTDataset(Dataset):\n",
    "    def __init__(self, images_file, labels_file):\n",
    "        self.images = load_mnist_images(images_file)\n",
    "        self.labels = load_mnist_labels(labels_file)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = self.images[index].astype(np.float32) / 255.0  # 归一化到 [0, 1]\n",
    "        label = self.labels[index]\n",
    "        return torch.tensor(image), torch.tensor(label)\n",
    "\n",
    "path = \"datasets/MNIST/raw/\"\n",
    "train_images_file = path + 'train-images-idx3-ubyte'\n",
    "train_labels_file = path + 'train-labels-idx1-ubyte'\n",
    "test_images_file = path + 't10k-images-idx3-ubyte'\n",
    "test_labels_file = path + 't10k-labels-idx1-ubyte'\n",
    "\n",
    "train_dataset = MNISTDataset(train_images_file, train_labels_file)\n",
    "test_dataset = MNISTDataset(test_images_file, test_labels_file)\n",
    "\n",
    "# 创建数据加载器\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=64, shuffle=False)\n",
    " \n",
    "############################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Define a MLP subclass of nn. Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### Write Your Code Here ###########\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)  # 第一层\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)  # 输出层\n",
    "        self.relu = nn.ReLU()  # 激活函数\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)  # 将28x28图像展平\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "############################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### Write Your Code Here ###########\n",
    "input_size = 28 * 28  # 图像展平后的尺寸\n",
    "hidden_size = 32 # 隐藏层神经元数量\n",
    "num_classes = 10  # 0-9\n",
    "\n",
    "model = MLP(input_size, hidden_size, num_classes)\n",
    "############################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " + Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### Write Your Code Here ###########\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "############################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ The optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### Write Your Code Here ###########\n",
    "import torch.optim as optim\n",
    "learning_rate = 0.001\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "############################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1, 1], Loss: 0.0115\n",
      "Epoch [1, 101], Loss: 0.0086\n",
      "Epoch [1, 201], Loss: 0.0354\n",
      "Epoch [1, 301], Loss: 0.0170\n",
      "Epoch [1, 401], Loss: 0.0503\n",
      "Epoch [1, 501], Loss: 0.0059\n",
      "Epoch [1, 601], Loss: 0.0377\n",
      "Epoch [1, 701], Loss: 0.0574\n",
      "Epoch [1, 801], Loss: 0.0221\n",
      "Epoch [1, 901], Loss: 0.0163\n",
      "Epoch [2, 1], Loss: 0.0299\n",
      "Epoch [2, 101], Loss: 0.0338\n",
      "Epoch [2, 201], Loss: 0.0139\n",
      "Epoch [2, 301], Loss: 0.0225\n",
      "Epoch [2, 401], Loss: 0.0312\n",
      "Epoch [2, 501], Loss: 0.0040\n",
      "Epoch [2, 601], Loss: 0.0288\n",
      "Epoch [2, 701], Loss: 0.0077\n",
      "Epoch [2, 801], Loss: 0.0649\n",
      "Epoch [2, 901], Loss: 0.0094\n",
      "Epoch [3, 1], Loss: 0.0705\n",
      "Epoch [3, 101], Loss: 0.0062\n",
      "Epoch [3, 201], Loss: 0.0244\n",
      "Epoch [3, 301], Loss: 0.0172\n",
      "Epoch [3, 401], Loss: 0.0195\n",
      "Epoch [3, 501], Loss: 0.0441\n",
      "Epoch [3, 601], Loss: 0.0112\n",
      "Epoch [3, 701], Loss: 0.0010\n",
      "Epoch [3, 801], Loss: 0.0186\n",
      "Epoch [3, 901], Loss: 0.0190\n",
      "Epoch [4, 1], Loss: 0.0105\n",
      "Epoch [4, 101], Loss: 0.0059\n",
      "Epoch [4, 201], Loss: 0.0138\n",
      "Epoch [4, 301], Loss: 0.0124\n",
      "Epoch [4, 401], Loss: 0.0096\n",
      "Epoch [4, 501], Loss: 0.0176\n",
      "Epoch [4, 601], Loss: 0.0469\n",
      "Epoch [4, 701], Loss: 0.0494\n",
      "Epoch [4, 801], Loss: 0.0032\n",
      "Epoch [4, 901], Loss: 0.0073\n",
      "Epoch [5, 1], Loss: 0.0149\n",
      "Epoch [5, 101], Loss: 0.0036\n",
      "Epoch [5, 201], Loss: 0.0081\n",
      "Epoch [5, 301], Loss: 0.0132\n",
      "Epoch [5, 401], Loss: 0.0213\n",
      "Epoch [5, 501], Loss: 0.0040\n",
      "Epoch [5, 601], Loss: 0.0400\n",
      "Epoch [5, 701], Loss: 0.0514\n",
      "Epoch [5, 801], Loss: 0.0051\n",
      "Epoch [5, 901], Loss: 0.0144\n"
     ]
    }
   ],
   "source": [
    "\n",
    "########### Write Your Code Here ###########\n",
    "num_epochs = 5  # 训练轮数\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i % 100 == 0:\n",
    "            print(f'Epoch [{epoch + 1}, {i+1}], Loss: {loss.item():.4f}')\n",
    "\n",
    "############################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the test images: 96.97%\n"
     ]
    }
   ],
   "source": [
    "########### Write Your Code Here ###########\n",
    "with torch.no_grad():\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    y_test=[]\n",
    "    y_predicted_cls=[]\n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        y_test.extend(labels.numpy())\n",
    "        y_predicted_cls.extend(predicted.numpy())\n",
    "\n",
    "    print(f'Accuracy of the model on the test images: {100 * correct / total:.2f}%')\n",
    "############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98       980\n",
      "           1       0.99      0.99      0.99      1135\n",
      "           2       0.96      0.97      0.97      1032\n",
      "           3       0.96      0.97      0.97      1010\n",
      "           4       0.98      0.96      0.97       982\n",
      "           5       0.98      0.95      0.96       892\n",
      "           6       0.96      0.97      0.97       958\n",
      "           7       0.98      0.96      0.97      1028\n",
      "           8       0.95      0.97      0.96       974\n",
      "           9       0.96      0.97      0.97      1009\n",
      "\n",
      "    accuracy                           0.97     10000\n",
      "   macro avg       0.97      0.97      0.97     10000\n",
      "weighted avg       0.97      0.97      0.97     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_test = np.array(y_test)\n",
    "y_predicted_cls = np.array(y_predicted_cls)\n",
    "\n",
    "#classification report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_predicted_cls))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
